<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daniel Becking</title>
    <link rel="icon" href="graphics/favicon.png" type="image/png">
    <style>
        :root {
            --mygreen: #4B5E44;
            --myrose: #BE7388;
            --textwidth: 909px
        }
        body {
            font-family: Helvetica, Arial, sans-serif;
            font-size: 16px;
            margin: 0;
            padding: 0;
            background-color: #fff;
        }
        .content {
            max-width: var(--textwidth);
            margin: 20px auto;
            padding: 30px;
            background: #fff;
            box-shadow: none;
            display: flex;
            flex-direction: row;
            align-items: flex-start;
        }
        .projects {
            max-width: var(--textwidth);
            margin: 20px auto;
            padding: 30px;
            background: #fff;
            box-shadow: none;
        }
        .news-box {
            max-width: var(--textwidth);
            margin: 20px auto;
            padding: 10px;
            background: #fff;
            box-shadow: none;
            line-height: 1.6;
        }
        .profile-img {
            margin-right: 20px;
            margin-top: 48px;
            flex-shrink: 0;
        }
        .profile-img img {
            width: 203px;
            height: auto;
            padding-right: 20px;
        }
        .name, .title {
            font-size: 24px;
            margin: 8px 0 0 0;
            color: black;
            text-align: left;
        }
        .pronouns, .subtitle {
            color: grey;
            margin-top: 5px;
            text-align: left;
        }
        .subsubtitle {
            font-style: italic;
            margin-top: -15px;
            margin-bottom: 10px;
        }
        .bio {
            flex-grow: 1;
            text-align: left;
            line-height: 1.6;
        }
        .bio a {
            color: var(--myrose);
            text-decoration: none;
        }
        .bio a:hover {
            text-decoration: underline;
        }
        .links {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            align-items: center;
        }
        .links a {
            text-decoration: none;
        }
        .links a:hover {
            background-color: #0C0E03;
        }
        .download-cv {
            text-decoration: none;
            color: #fff;
            background-color: var(--mygreen);
        }
        .download-cv::before {
            content: '\2193';
            color: #fff;
            margin-right: 5px;
            vertical-align: middle;
        }
        .mail-button {
            text-decoration: none;
            color: #fff;
            background-color: var(--mygreen);
        }
        .mail-icon {
            color: #fff;
            font-size: 1.5em;
            margin-right: 5px;
            vertical-align: middle;
        }
        .mail-button span, .mail-button {
            vertical-align: middle;
        }
        .bio p {
            margin-bottom: 1em;
        }
        hr {
            border: none;
            border-top: 1px solid #ccc;
            margin: 20px 0;
        }
        .projects .title {
            margin-bottom: 10px;
        }
        .project {
            display: flex;
            align-items: center;
            margin-bottom: 40px;
        }
        .project img {
            width: 303px;
            height: auto;
            margin-right: 20px;
            object-fit: cover;
        }
        .project-description {
            flex-grow: 1;
            text-align: left;
            line-height: 1.6;
        }
        .buttons-container {
            display: flex;
            gap: 10px;
            text-align: left;
        }
        .button {
            text-decoration: none;
            color: #fff;
            background-color: var(--mygreen);
            padding: 8px 12px;
            margin-right: 10px;
            line-height: 1;
        }
        .button:hover {
            background-color: #0C0E03;
        }
        .special-link {
            color: var(--myrose);
            text-decoration: none;
            font-weight: bold;
        }
        .news-box .title {
            margin-bottom: 15px;
        }
        .spaced-news-list li {
            margin-bottom: 10px;
            margin-left: 20px;
        }

        .download-cv, .mail-button, .button {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            height: 30px;
            padding: 0 8px;
            box-sizing: border-box;
            font-size: 14px;
        }
        .links img {
            height: 30px;
            width: auto;
            padding: 0 0px;
        }
        .links a:not(.download-cv):not(.mail-button) {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            height: 30px;
            padding: 0;
            box-sizing: border-box;
        }

        @media (max-width: 768px) {
            body {
            font-size: 15px;
            }
            .content {
                flex-direction: column;
                align-items: center;
            }
            .profile-img {
                margin-right: 0;
                margin-top: 0;
                align-items: center;
            }
            .profile-img img {
                width: 250px;
                max-width: 100%;
                height: auto;
            }
            .bio {
                text-align: left;
            }
            .links {
                justify-content: center;
            }
            .project {
                flex-direction: column;
                align-items: center;
            }
            .project img {
                margin-right: 0;
                margin-bottom: 10px;
                width: 300px;
                height: auto;
                max-width: 100%;
            }
        }
        @media (max-width: 480px) {
            .profile-img img {
                width: 200px;
                max-width: 100%;
                height: auto;
            }
            .name {
                font-size: 1.2em;
            }
            .pronouns {
                font-size: 0.9em;
            }
            .button {
                padding: 4px 6px;
                font-size: 0.8em;
            }
            .download-cv {
                padding: 6px 6px;
                font-size: 0.8em;
            }
            .mail-button {
                padding: 0px 6px;
                font-size: 0.8em;
            }
            .project img {
                width: 300px;
                max-width: 100%;
                height: auto;
            }
            .content, .projects, .news-box {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="content">
        <div class="profile-img">
            <img src="graphics/db.jpeg" alt="portrait">
            <div class="name">Daniel Becking</div>
            <div class="pronouns">(he/him)</div>
        </div>
        <div>
            <hr>
            <div class="bio">
                I am a research associate and Ph.D. student in the <a href="https://www.hhi.fraunhofer.de/en/departments/ai/research-groups/efficient-deep-learning.html" target="_blank"><strong>Efficient Deep Learning Group</strong></a> at the Fraunhofer Heinrich-Hertz-Institute (HHI) and the Technical University of Berlin, supervised by <a href="https://iphome.hhi.de/samek/" target="_blank"><strong>Wojciech Samek</strong></a>.

                <p>My current research interests lie in the domain of <strong>neural codecs</strong> like language
                    model-based general-purpose compressors. I am also working on methods specifically tailored to
                    <strong>compression of neural networks</strong> and the efficient <strong>transmission of
                        incremental neural data</strong>, e.g., within distributed learning scenarios like federated
                    or split learning. My methods leverage <strong>explainable AI (XAI)</strong> techniques and concepts
                    of <strong>information theory</strong>.<br>

                    As a regular attendee of Moving Picture Experts Group (MPEG) meetings since 2020, I have contributed several compression tools and syntax to the
                    first and second editions of the <a href="https://www.iso.org/standard/85545.html" target="_blank"><strong>ISO/IEC 15938-17 </strong></a>
                    standard for
                    <a href="https://www.hhi.fraunhofer.de/en/departments/ai/research-groups/efficient-deep-learning/research-topics/neural-network-compression.html" target="_blank" class="special-link">Neural Network Coding (NNC)</a>.<br>

                    I completed my M.Sc. in Biomedical Engineering in 2020, under the guidance of Klaus-Robert M端ller at
                    the Technical University of Berlin.<br>

                    Before joining Fraunhofer HHI, and during my bachelor's studies in Microsystems Engineering, I was part
                    of the Sensor Nodes & Embedded Microsystems group at Fraunhofer IZM. This experience was invaluable
                    while working on our <a href="https://ieeexplore.ieee.org/document/9440253" target="_blank"><strong>FantastIC4 low-power neural network accelerator</strong></a>.
            </div>
            <hr>
            <div class="links">
                <a href="https://www.linkedin.com/in/danielbecking" target="_blank">
                    <img src="https://img.shields.io/badge/LinkedIn-4B5E44?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn">
                </a>
                <a href="https://scholar.google.com/citations?user=9iCPs2AAAAAJ" target="_blank">
                    <img src="https://img.shields.io/badge/Google%20Scholar-4B5E44?style=for-the-badge&logo=google-scholar&logoColor=white" alt="Google Scholar">
                </a>
                <a href="https://github.com/d-becking" target="_blank">
                    <img src="https://img.shields.io/badge/GitHub-4B5E44?style=for-the-badge&logo=github&logoColor=white" alt="GitHub">
                </a>
                <a href="https://x.com/danielbecking" target="_blank">
                    <img src="https://img.shields.io/badge/X-4B5E44?style=for-the-badge&logo=x&logoColor=white" alt="X">
                </a>
                <a href="mailto:&#105;&#x6e;&#102;&#x6f;&#64;&#x64;&#98;&#x65;&#99;&#x6b;&#105;&#x6e;&#103;&#x2e;&#99;&#x6f;&#109;" class="mail-button"><span class="mail-icon">
                    &#9993;</span> Mail</a>
                <a href="data/CV_2025.pdf" target="_blank" download class="download-cv">
                    CV (2025)
                </a>
            </div>
        </div>
    </div>

    <div class="news-box">
        <div class="title">Latest News and Highlights</div>
        <hr>
        <ul class="spaced-news-list">

            <li><strong>2025/07</strong>:
                I'm a speaker at the
                <a href="https://aiforgood.itu.int/event/ai-and-machine-learning-in-communication-networks-summit25-day1/" target="_blank" class="special-link">AI and Machine Learning in Communication Networks Workshop</a>,
                hosted at ITU's <i>AI for Good Global Summit</i> (8-11 July).
            </li>

            <li><strong>2025/04</strong>:
                Our work <i>Efficient Federated Learning Tiny Language Models for Mobile Network Feature Prediction</i> was accepted for the
                <a href="https://www.eucnc.eu" target="_blank" class="special-link">2025 EuCNC & 6G Summit</a> poster session (June 4).
                <a href="https://arxiv.org/abs/2504.01947" target="_blank" class="special-link">[Paper]</a>
                <a href="https://datacloud.hhi.fraunhofer.de/s/B3zXYPN55p4dQzZ" target="_blank" class="special-link"> [Poster]</a>
            </li>

            <li><strong>2024/11</strong>:
                Invited to discuss with fellow researchers and present on <i>NN Coding for Energy-Efficient Communication in FL</i> at the workshop
                <a href="https://www.linkedin.com/posts/bifoldberlin_on-friday-november-29-2024-bifold-researchersprof-activity-7269591229674237952-0VbM?utm_source=share&utm_medium=member_desktop" target="_blank" class="special-link">The European AI Act: Developing a Technical Perspective</a>
                on Nov 29 at <a href="https://www.bifold.berlin" target="_blank" class="special-link">BIFOLD</a>/TU Berlin.
            </li>

            <li><strong>2024/07</strong>: At the <a href="https://www.mpeg.org/meetings/mpeg-147/" target="_blank" class="special-link">147th MPEG meeting</a>
                 I contributed to the finalization of the <a href="https://standards.iso.org/iso-iec/15938/-18/ed-2/en/" target="_blank" class="special-link">Conformance
                    and Reference Software (INCTM)</a> for enc-/decoding bitstreams in compliance with the
                <a href="https://www.iso.org/standard/85545.html" target="_blank" class="special-link">Neural Network Coding (NNC) ed. 2 standard</a>. Additionally,
                we issued a preliminary working draft for the future of NNC and began collecting potential new use cases.</li>

            <li><strong>2024/01</strong>: IEEE Transactions on Multimedia published my journal paper on coding and transmitting neural data across devices for efficient distributed learning communication. <a href="https://ieeexplore.ieee.org/document/10412190" target="_blank" class="special-link">[Paper]</a></li>

            <li><strong>2023/07</strong>: <a href="https://neuralcompression.github.io/workshop23" target="_blank" class="special-link">ICML Neural Compression Workshop</a>: NNCodec was awarded a Spotlight. <a href="https://openreview.net/forum?id=5VgMDKUgX0" target="_blank" class="special-link"> [Paper]</a>
            <a href="https://datacloud.hhi.fraunhofer.de/s/QFKiqCYE3Q8ptAy" target="_blank" class="special-link"> [Poster]</a>
            </li>

            <li><strong>2022/06</strong>: <a href="https://sites.google.com/view/fedvision" target="_blank" class="special-link">CVPR FedVision Workshop</a>:
                I gave a talk on Adaptive Differential Filters for Fast and Communication-Efficient Federated Learning.
                <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.crcv.ucf.edu%2Fchenchen%2FFedVision-Workshop-CVPR2022%2FBecking_FSFL_FedVision_CVPR22.pdf&sa=D&sntz=1&usg=AOvVaw0pbqLqE-TsYOUZloa9GTlY" target="_blank" class="special-link">[Slides]</a>
                <a href="https://youtu.be/A9nEWqGriZ4" target="_blank" class="special-link">[Video]</a>
                <a href="https://openaccess.thecvf.com/content/CVPR2022W/FedVision/html/Becking_Adaptive_Differential_Filters_for_Fast_and_Communication-Efficient_Federated_Learning_CVPRW_2022_paper.html" target="_blank" class="special-link">[Paper]</a>
            </li>

            <li><strong>2022/04</strong>: The "xxAI - Beyond Explainable AI" book, including my chapter <i>ECQx: Explainability-Driven Quantization for Low-Bit and Sparse DNNs</i>, is now published.
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-04083-2_14" target="_blank" class="special-link">[Chapter]</a>
                <a href="https://github.com/d-becking/ECQx" target="_blank" class="special-link">[Code]</a>
            </li>

            <li><strong>2021/05</strong>:
                We teamed up with the TU Berlin on <i>FantastIC4</i>, a 4-bit hardware-software co-design for Multilayer Perceptrons in FPGA & ASIC.
                Check the architecture and results in
                <a href="https://ieeexplore.ieee.org/abstract/document/9440253" target="_blank" class="special-link">IEEE Open Journal of Circuits and Systems</a>.
            </li>

            <li><strong>2020/06</strong>: The investigations from my
                <a href="https://www.researchgate.net/profile/Daniel-Becking/publication/354987516_Finding_Storage-_and_Compute-Efficient_Convolutional_Neural_Networks/links/6156f041a6fae644fbb6a2a8/Finding-Storage-and-Compute-Efficient-Convolutional-Neural-Networks.pdf" target="_blank" class="special-link">master's thesis </a>
                led to the <i>Entropy-Constrained Trained Ternarization (EC2T)</i> paper, which will be presented as oral (virtually) at the CVPR Workshop on Efficient Deep Learning in Computer Vision.
                <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w40/Marban_Learning_Sparse__Ternary_Neural_Networks_With_Entropy-Constrained_Trained_Ternarization_CVPRW_2020_paper.html" target="_blank" class="special-link">[Paper]</a>
                <a href="https://github.com/d-becking/efficientCNNs" target="_blank" class="special-link">[Code]</a>
            </li>

            <li><strong>2019/12</strong>: <a href="https://micronet-challenge.github.io/leaderboard.html" target="_blank" class="special-link">NeurIPS MicroNet Challenge</a>: My submitted ternary neural networks ranked among the top-5. <a href="https://github.com/d-becking/neurips-2019-micronet-challenge/tree/master" target="_blank" class="special-link">[Code]</a></li>

        </ul>
        <hr>
    </div>

    <div class="projects">
        <div class="title">Selected Publications and Projects</div>
        <hr>
        <div class="project">
            <img src="graphics/PUT_revision.png" alt="TMM">
            <div class="project-description">
                <h4>Neural Network Coding of Difference Updates for Efficient Distributed Learning Communication <div class="subtitle">IEEE Transactions on Multimedia Vol. 26, 2024</div></h4>
                <div class="subsubtitle">Co-authors: Karsten M端ller, Paul Haase, Heiner Kirchhoffer, Gerhard Tech, Wojciech Samek, Heiko Schwarz, Detlev Marpe, Thomas Wiegand</div>
                To improve the efficiency of frequent neural data communication in distributed learning, we present a set of new compression tools specifically tailored for coding incremental neural updates.
                These include <strong>Federated BatchNorm folding</strong> (FedBNF), structured and unstructured
                sparsification, tensor row skipping, quantization optimization and temporal adaptations for improved context-adaptive binary arithmetic coding
                (<a href="https://www.hhi.fraunhofer.de/en/departments/vca/research-groups/video-coding-technologies/research-topics/past-research-topics/context-based-adaptive-binary-arithmetic-coding-cabac.html" target="_blank" class="special-link">CABAC</a>).
                Furthermore, we introduce the parameter update tree (PUT) syntax, enabling identification of different neural network parameter subsets and their relationships in
                (a)synchronous communication paradigms from the bitstream. We benchmark these tools in multiple federated and
                <strong>SplitFed</strong> scenarios using a variety of models including <strong>ViTs</strong>.
                <p><div class="buttons-container">
                    <a href="https://ieeexplore.ieee.org/document/10412190" target="_blank" class="button">View Paper (IEEE Xplore Open Access)</a>
                </div></p>
            </div>
        </div>
        <hr>
        <div class="project">
            <img src="graphics/nncodec.png" alt="NNCodec">
            <div class="project-description">
                <h4>[Spotlight] Paper at the Neural Compression Workshop <div class="subtitle">ICML 2023</div></h4>
                <div class="subsubtitle">Co-authors: Paul Haase, Heiner Kirchhoffer, Karsten M端ller, Wojciech Samek, Detlev Marpe</div>
                NNCodec is the first open-source, standard-compliant implementation of the
                <a href="https://www.hhi.fraunhofer.de/en/departments/ai/research-groups/efficient-deep-learning/research-topics/neural-network-compression.html" target="_blank" class="special-link">Neural Network Coding (NNC)</a> standard
                <a href="https://www.iso.org/standard/85545.html" target="_blank" class="special-link">(ISO/IEC 15938-17)</a>. The paper outlines the software architecture and main coding tools.
                We analyzed the underlying neural network weight distributions and information content to examine higher compression gains compared to other entropy codes like Huffman coding.
                Notably, the average codeword length of NNCodec often falls <strong>below the Shannon entropy bound</strong>.
                Furthermore, by introducing specially trained local scaling parameters, NNCodec can effectively compensate for quantization errors to a certain extent.
                <p><div class="buttons-container">
                    <a href="https://openreview.net/forum?id=5VgMDKUgX0" target="_blank" class="button">View Paper (OpenReview)</a>
                    <a href="https://github.com/fraunhoferhhi/nncodec" target="_blank" class="button">View Code</a>
                    <a href="https://github.com/d-becking/nncodec-icml-2023-demo" target="_blank" class="button">Demo & Poster</a>
                </div></p>
            </div>
        </div>
        <hr>
        <div class="project">
            <img src="graphics/BerDiBa.png" alt="BerDiBa">
            <div class="project-description">
                <h4>BerDiBa: Berlin Digital Rail Operations <div class="subtitle">funded by the Investitionsbank Berlin and the EU</div></h4>
                <div class="subsubtitle">Co-authors: Nico Harder, Maximilian Dreyer</div>
                In the <a href="https://www.hhi.fraunhofer.de/en/departments/ai/projects/berdiba.html" target="_blank" class="special-link">BerDiBa</a>
                project, I developed algorithms to generate highly efficient models for semantic segmentation of image data from
                the driver's cab perspective in autonomous trains. I enhanced my
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-04083-2_14" target="_blank" class="special-link">explainability-driven, entropy-constrained
                quantization method (ECQ<sup>x</sup>)</a>, reducing DeepLabV3 precision to 2-4 bits and introducing high sparsity without
                compromising performance. Additionally, we applied a specialized <strong>semantic knowledge distillation</strong> technique to
                extract compact student networks. Using
                <a href="https://www.nature.com/articles/s42256-023-00711-8" target="_blank" class="special-link">Concept Relevance Propagation (CRP)</a>,
                we identified network subgraphs highly <i>relevant</i> for specific classes&mdash;or concepts within classes&mdash;, which can be jointly
                activated or deactivated through a gating mechanism: <strong>Mixture-of-Relevant-Experts</strong>.
                <p><div class="buttons-container">
                    <a href="data/BerDiBa_MS_AP1-2_8.pdf" target="_blank" class="button">Slides</a>
                </div></p>
            </div>
        </div>
        <hr>
        <div class="project">
            <img src="graphics/ecqx.png" alt="BerDiBa">
            <div class="project-description">
                <h4>ECQx: Explainability-Driven Quantization for Low-Bit and Sparse DNNs
                    <div class="subtitle">xxAI - Beyond Explainable AI, Lecture Notes in Computer Science Vol. 13200</div></h4>
                <div class="subsubtitle">Co-authors: Maximilian Dreyer, Wojciech Samek, Karsten M端ller, Sebastian Lapuschkin</div></h4>
                The ECQ<sup>x</sup> method leverages concepts of explainable AI (XAI) and of information theory in the quantization-aware training paradigm: Instead of assigning weight values solely based
                on their proximity to the quantization clusters, the method considers weight relevances obtained from
                <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140" target="_blank" class="special-link">Layer-wise Relevance Propagation (LRP)</a>
                and the information content of the clusters (entropy optimization).
                A key insight is that <strong>weight magnitude is not necessarily correlated with weight relevance</strong>.
                This allows us to preserve relevant weights from being quantized to zero while simultaneously deactivating irrelevant high-magnitude weights or neurons.

                <p><div class="buttons-container">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-031-04083-2_14" target="_blank" class="button">View Paper (Springer Link)</a>
                    <a href="https://github.com/d-becking/ECQx" target="_blank" class="button">View Code</a>
                </div></p>
            </div>
        </div>
        <hr>
        Find a complete list of publications on <a href="https://scholar.google.com/citations?user=9iCPs2AAAAAJ" target="_blank" class="special-link">GScholar</a>.
    </div>
</body>
<footer style="display: flex; justify-content: center; align-items: center; height: 60px; background-color: #f4f4f4;">
    <a href="impressum.html" target="_blank" style="color: grey; text-decoration: none; font-size: 16px;">Impressum</a>
</footer>
</html>